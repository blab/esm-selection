{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Carlos/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import requests\n",
    "from augur.utils import json_to_tree\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import MutableSeq\n",
    "from Bio.SeqRecord import SeqRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract fasta for each node\n",
    "\n",
    "def apply_muts_to_root(root_seq, list_of_muts):\n",
    "    \"\"\"\n",
    "    Apply a list of mutations to the root sequence\n",
    "    to find the sequence at a given node. The list of mutations\n",
    "    is ordered from root to node, so multiple mutations at the\n",
    "    same site will correctly overwrite each other\n",
    "    \"\"\"\n",
    "\n",
    "    # make the root sequence mutatable\n",
    "    root_plus_muts = MutableSeq(root_seq)\n",
    "\n",
    "    # apply all mutations to root sequence\n",
    "    for mut in list_of_muts:\n",
    "        # subtract 1 to deal with biological numbering vs python\n",
    "        mut_site = int(mut[1:-1])-1\n",
    "        # get the nuc that the site was mutated TO\n",
    "        mutation = mut[-1]\n",
    "        # apply mutation\n",
    "        root_plus_muts[mut_site] = mutation\n",
    "\n",
    "\n",
    "    return root_plus_muts\n",
    "\n",
    "\n",
    "def getNodeSequences(gene, local_files, tree_file, root_file):\n",
    "    \"\"\"\n",
    "    Get the sequence at each node in the given tree and\n",
    "    save them as a FASTA file\n",
    "    \"\"\"\n",
    "    # if we are fetching the JSONs from a URL\n",
    "    if local_files == \"False\":\n",
    "        # fetch the tree JSON from URL\n",
    "        tree_json = requests.get(tree_file, headers={\"accept\":\"application/json\"}).json()\n",
    "        # put tree in Bio.phylo format\n",
    "        tree = json_to_tree(tree_json)\n",
    "        # fetch the root JSON from URL\n",
    "        root_json = requests.get(root_file, headers={\"accept\":\"application/json\"}).json()\n",
    "        # get the nucleotide sequence of root\n",
    "        root_seq_nuc = root_json[gene]\n",
    "\n",
    "    # if we are using paths to local JSONs\n",
    "    elif local_files == \"True\":\n",
    "        # load tree\n",
    "        with open(tree_file, 'r') as f:\n",
    "            tree_json = json.load(f)\n",
    "        # put tree in Bio.phylo format\n",
    "        tree = json_to_tree(tree_json)\n",
    "        # load root sequence file\n",
    "        with open(root_file, 'r') as f:\n",
    "            root_json = json.load(f)\n",
    "        # get the nucleotide sequence of root\n",
    "        root_seq_nuc = root_json[gene]\n",
    "\n",
    "    ## Now find the node sequences\n",
    "\n",
    "    # initialize list to store sequence records for each node\n",
    "    sequence_records = []\n",
    "\n",
    "    # find sequence at each node in the tree (includes internal nodes and terminal nodes)\n",
    "    for node in tree.find_clades():\n",
    "\n",
    "        # get path back to the root\n",
    "        path = tree.get_path(node)\n",
    "\n",
    "        # get all  mutations relative to root\n",
    "        muts = [branch.branch_attrs['mutations'].get(gene, []) for branch in path]\n",
    "        # flatten the list of nucleotide mutations\n",
    "        muts = [item for sublist in muts for item in sublist]\n",
    "        # get sequence at node\n",
    "        node_seq = apply_muts_to_root(root_seq_nuc, muts)\n",
    "\n",
    "        sequence_records.append(SeqRecord(node_seq, node.name, '', ''))\n",
    "\n",
    "    SeqIO.write(sequence_records, f\"nodeSeqs_{gene}.fasta\", \"fasta\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    \"\"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=__doc__,\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
    "    )\n",
    "    parser.add_argument(\"--gene\", default=\"nuc\",\n",
    "        help=\"Name of gene to return AA sequences for. 'nuc' will return full geneome nucleotide seq\")\n",
    "    parser.add_argument(\"--local-files\", default=\"False\",\n",
    "        help=\"Toggle this on if you are supplying local JSON files for the tree and root sequence.\" +\n",
    "             \"Default is to fetch them from a URL\")\n",
    "    parser.add_argument(\"--tree\", default=\"https://data.nextstrain.org/ncov_gisaid_global_all-time.json\",\n",
    "        help=\"URL for the tree.json file, or path to the local JSON file if --local-files=True\")\n",
    "    parser.add_argument(\"--root\", default=\"https://data.nextstrain.org/ncov_gisaid_global_all-time_root-sequence.json\",\n",
    "        help=\"URL for the root-sequence.json file, or path to the local JSON file if --local-files=True\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    getNodeSequences(args.gene, args.local_files, args.tree, args.root)\n",
    "    \"\"\"\n",
    "\n",
    "    args_gene = \"PB2\"\n",
    "    #args_gene = \"nuc\"\n",
    "    args_local_files = \"True\"\n",
    "    args_tree = \"/Users/Carlos/Downloads/h3n2_60y_pb2.json\"\n",
    "    args_root = \"/Users/Carlos/Downloads/h3n2_60y_pb2_root-sequence_Amino.json\"\n",
    "\n",
    "    getNodeSequences(args_gene, args_local_files, args_tree, args_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get terminals nodes for each internal node in tree\n",
    "\n",
    "def collect_terminal_nodes(node):\n",
    "    \"\"\"\n",
    "    Recursively collect terminal nodes (nodes without children) for each node in the tree.\n",
    "    \"\"\"\n",
    "    name = node.get(\"name\", \"(unnamed)\")\n",
    "    children = node.get(\"children\", [])\n",
    "    \n",
    "    # If the node has no children, it's a terminal node\n",
    "    if not children:\n",
    "        return [name]\n",
    "    \n",
    "    # Otherwise, collect terminal nodes from all children\n",
    "    terminal_nodes = []\n",
    "    for child in children:\n",
    "        terminal_nodes.extend(collect_terminal_nodes(child))\n",
    "    \n",
    "    return terminal_nodes\n",
    "\n",
    "def map_terminal_nodes(node):\n",
    "    \"\"\"\n",
    "    Create a mapping of each node to its terminal nodes.\n",
    "    \"\"\"\n",
    "    name = node.get(\"name\", \"(unnamed)\")\n",
    "    children = node.get(\"children\", [])\n",
    "    \n",
    "    # Collect terminal nodes for this node\n",
    "    terminal_nodes = collect_terminal_nodes(node)\n",
    "    node_terminal_map[name] = terminal_nodes\n",
    "    \n",
    "    # Recurse into each child\n",
    "    for child in children:\n",
    "        map_terminal_nodes(child)\n",
    "\n",
    "# Load tree JSON\n",
    "with open(\"/Users/Carlos/Downloads/h3n2_60y_pb2.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Entry point (usually under 'tree' or 'nodes')\n",
    "tree_root = data.get(\"tree\", data)  # Adjust depending on JSON structure\n",
    "\n",
    "# Dictionary to store the mapping of nodes to their terminal nodes\n",
    "node_terminal_map = {}\n",
    "\n",
    "# Map terminal nodes for each node\n",
    "map_terminal_nodes(tree_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and clean up the frequency JSON\n",
    "\n",
    "json_fh_frequency = open(\"/Users/Carlos/Downloads/h3n2_60y_pb2_tip-frequencies.json\", \"r\")\n",
    "json_dict_frequency = json.load(json_fh_frequency)\n",
    "\n",
    "del json_dict_frequency[\"pivots\"]\n",
    "del json_dict_frequency[\"generated_by\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get frequency sums for all nodes\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Output dictionary\n",
    "summed_frequencies = {}\n",
    "\n",
    "# Sum frequencies\n",
    "for node, terminals in node_terminal_map.items():\n",
    "    summed = None\n",
    "    for terminal in terminals:\n",
    "        if terminal in json_dict_frequency:\n",
    "            freqs = json_dict_frequency[terminal][\"frequencies\"]\n",
    "            if summed is None:\n",
    "                summed = freqs.copy()\n",
    "            else:\n",
    "                summed = [x + y for x, y in zip(summed, freqs)]\n",
    "    if summed is not None:\n",
    "        summed_frequencies[node] = summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out terminal nodes\n",
    "\n",
    "filtered_dict = {key: value for key, value in summed_frequencies.items() if key.startswith(\"NODE_\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max frequency for each internal node\n",
    "\n",
    "max_values = {key: max(values) for key, values in filtered_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your multi-FASTA file\n",
    "fasta_path = \"/Users/Carlos/Desktop/Bedford/esm-selection/nodeSeqs_PB2.fasta\"\n",
    "\n",
    "# Create a new dictionary to hold scores and sequences\n",
    "node_data = {}\n",
    "\n",
    "# Load FASTA sequences into a dictionary\n",
    "fasta_dict = SeqIO.to_dict(SeqIO.parse(fasta_path, \"fasta\"))\n",
    "\n",
    "# Add sequences to the node_data\n",
    "for node, score in max_values.items():\n",
    "    if node in fasta_dict:\n",
    "        node_data[node] = {\n",
    "            \"max_frequency\": score,\n",
    "            \"sequence\": str(fasta_dict[node].seq)\n",
    "        }\n",
    "    else:\n",
    "        node_data[node] = {\n",
    "            \"max_frequency\": score,\n",
    "            \"sequence\": None  # or handle missing sequences as needed\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "#for node, data in node_data.items():\n",
    "#    print(f\"{node} - max_frequency: {data['max_frequency']}, Sequence: {data['sequence'][:30]}...\")  # preview first 30 bases\n",
    "\n",
    "#node_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(node_data, orient='index')\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.rename(columns={df.columns[0]: 'node'})\n",
    "\n",
    "df_to_csv = df.to_csv(\"/Users/Carlos/Desktop/Bedford/esm-selection/Max_Freq_Fasta.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
