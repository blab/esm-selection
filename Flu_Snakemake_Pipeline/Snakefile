SEGMENTS = ["pb2", "pb1", "pa", "np", "na", "mp", "ns", "ha"]
#SEGMENTS = ["pb2", "pb1"]


rule all:
    input:
        expand(
            "max_freqs_log_likelyhood_15B/Max_Freq_Fasta_LL_15B_{segment}.csv",
            segment=SEGMENTS,
        ),
        expand(
            "max_freqs_log_likelyhood_3B/Max_Freq_Fasta_LL_3B_{segment}.csv",
            segment=SEGMENTS,
        ),
        expand(
            "max_freqs_log_likelyhood_650M/Max_Freq_Fasta_LL_650M_{segment}.csv",
            segment=SEGMENTS,
        ),


rule translate_nucleotide_json:
    input:
        json_tree="h3n2_Sequences/h3n2_60y_{segment}.json",
        json_root="h3n2_Sequences/h3n2_60y_{segment}_root-sequence.json",
        script="scripts/translate_nucleotide_to_protein.py",
    output:
        "root_tree_translated/h3n2_60y_{segment}_root-sequence.json",
    conda:
        "envs/nextstrain_env.yaml"
    container:
        "envs/nextstrain-base.sif"
    shell:
        """
        mkdir -p root_tree_translated
        python {input.script} --tree {input.json_tree} --root {input.json_root} --segment {wildcards.segment}
        mv h3n2_60y_{wildcards.segment}_root-sequence.json root_tree_translated/h3n2_60y_{wildcards.segment}_root-sequence.json
        """

rule extract_node_fastas:
    input:
        json_tree="h3n2_Sequences/h3n2_60y_{segment}.json",
        json_root="root_tree_translated/h3n2_60y_{segment}_root-sequence.json",
        script="scripts/extract_fasta_nodes.py",
    output:
        "node_fastas/nodeSeqs_{segment}.fasta",
    conda:
        "envs/nextstrain_env.yaml"
    container:
        "envs/nextstrain-base.sif"
    shell:
        """
        mkdir -p node_fastas
        python {input.script} --gene {wildcards.segment} --local-files True --tree {input.json_tree} --root {input.json_root} 
        mv nodeSeqs_{wildcards.segment}.fasta node_fastas/nodeSeqs_{wildcards.segment}.fasta
        """


rule extract_max_freq:
    input:
        json_tree="h3n2_Sequences/h3n2_60y_{segment}.json",
        node_fastas="node_fastas/nodeSeqs_{segment}.fasta",
        json_tip_freq="h3n2_Sequences/h3n2_60y_{segment}_tip-frequencies.json",
        script="scripts/extract_max_freq.py",
    output:
        "max_freqs/Max_Freq_Fasta_{segment}.csv",
    conda:
        "envs/nextstrain_env.yaml"
    container:
        "envs/nextstrain-base.sif"
    shell:
        """
        mkdir -p max_freqs
        time python {input.script} --segment {wildcards.segment} --tree {input.json_tree} --tip-freq {input.json_tip_freq} --node-fasta {input.node_fastas}
        mv Max_Freq_Fasta_{wildcards.segment}.csv max_freqs/Max_Freq_Fasta_{wildcards.segment}.csv
        """


rule calc_ll_esm_650M:
    input:
        max_freq="max_freqs/Max_Freq_Fasta_{segment}.csv",
        script="scripts/calc_ll_esm.py",
    output:
        "max_freqs_log_likelyhood_650M/Max_Freq_Fasta_LL_650M_{segment}.csv",
    shell:
        """
        mkdir -p max_freqs_log_likelyhood_650M
        start_time=$(date +%s)
        python {input.script} --max_freq {input.max_freq} --segment {wildcards.segment} --model esm2_t33_650M_UR50D
        end_time=$(date +%s)
        runtime=$((end_time - start_time))
        
        # Add runtime as a new column to the output CSV
        awk -v runtime=$runtime 'BEGIN {{FS=OFS=","}} NR==1 {{print $0, "runtime"}} NR>1 {{print $0, runtime}}' \
            Max_Freq_Fasta_LL_{wildcards.segment}_esm2_t33_650M_UR50D.csv > temp_{wildcards.segment}.csv
        
        mv temp_{wildcards.segment}.csv max_freqs_log_likelyhood_650M/Max_Freq_Fasta_LL_650M_{wildcards.segment}.csv
        """

rule calc_ll_esm_3B:
    input:
        max_freq="max_freqs/Max_Freq_Fasta_{segment}.csv",
        script="scripts/calc_ll_esm.py",
    output:
        "max_freqs_log_likelyhood_3B/Max_Freq_Fasta_LL_3B_{segment}.csv",
    shell:
        """
        mkdir -p max_freqs_log_likelyhood_3B
        start_time=$(date +%s)
        python {input.script} --max_freq {input.max_freq} --segment {wildcards.segment} --model esm2_t36_3B_UR50D
        end_time=$(date +%s)
        runtime=$((end_time - start_time))
        
        # Add runtime as a new column to the output CSV
        awk -v runtime=$runtime 'BEGIN {{FS=OFS=","}} NR==1 {{print $0, "runtime"}} NR>1 {{print $0, runtime}}' \
            Max_Freq_Fasta_LL_{wildcards.segment}_esm2_t36_3B_UR50D.csv > temp_{wildcards.segment}.csv
        
        mv temp_{wildcards.segment}.csv max_freqs_log_likelyhood_3B/Max_Freq_Fasta_LL_3B_{wildcards.segment}.csv
        """

rule calc_ll_esm_15B:
    input:
        max_freq="max_freqs/Max_Freq_Fasta_{segment}.csv",
        script="scripts/calc_ll_esm.py",
    output:
        "max_freqs_log_likelyhood_15B/Max_Freq_Fasta_LL_15B_{segment}.csv",
    shell:
        """
        mkdir -p max_freqs_log_likelyhood_15B
        start_time=$(date +%s)
        python {input.script} --max_freq {input.max_freq} --segment {wildcards.segment} --model esm2_t48_15B_UR50D
        end_time=$(date +%s)
        runtime=$((end_time - start_time))
        
        # Add runtime as a new column to the output CSV
        awk -v runtime=$runtime 'BEGIN {{FS=OFS=","}} NR==1 {{print $0, "runtime"}} NR>1 {{print $0, runtime}}' \
            Max_Freq_Fasta_LL_{wildcards.segment}_esm2_t48_15B_UR50D.csv > temp_{wildcards.segment}.csv
        
        mv temp_{wildcards.segment}.csv max_freqs_log_likelyhood_15B/Max_Freq_Fasta_LL_15B_{wildcards.segment}.csv
        """

rule generate_max_freq_v_ll_plots:
    input:
        max_freq_ll="max_freqs_log_likelyhood/Max_Freq_Fasta_LL_{segment}.csv",
        script="scripts/freq_v_ll_plots.py",
    output:
        "max_freqs_log_likelyhood_plots/Max_Freq_Vs_LL_{segment}.png",
    conda:
        "envs/data_analysis_env.yaml"
    shell:
        """
        mkdir -p max_freqs_vs_log_likelyhood_plots
        python {input.script} --Max_Freq_LL {input.max_freq_ll} --segment {wildcards.segment}
        mv Max_Freq_Vs_LL_{wildcards.segment}.png max_freqs_log_likelyhood_plots/Max_Freq_Vs_LL_{wildcards.segment}.png
        """
